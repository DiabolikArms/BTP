{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37f73c5-cd6b-4753-a6a2-cf3f53ea66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import wget\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb0cc99-d924-4ae3-aa7d-f6e3ee976c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data from the combined_articles.pkl file\n",
    "with open('combined_articles.pkl', 'rb') as file:\n",
    "    combined_articles = pickle.load(file)\n",
    "\n",
    "# Initialize the all_article_hrefs list\n",
    "all_article_hrefs = []\n",
    "\n",
    "# Assuming combined_articles is a list of pairs, append them to all_article_hrefs\n",
    "for article in combined_articles:\n",
    "    all_article_hrefs.append(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676858de-f7ac-4f6a-afe8-3fe3c7d09292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split all_article_hrefs into chunks of 1000\n",
    "chunk_size = 1000\n",
    "chunks = [all_article_hrefs[i:i + chunk_size] for i in range(0, len(all_article_hrefs), chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d73aa9-4231-4d27-b71b-a209d37a6a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/28\n",
      "Chunk 1 saved as article_chunks\\article_hrefs_chunk_1.pkl\n",
      "Processing chunk 2/28\n",
      "Chunk 2 saved as article_chunks\\article_hrefs_chunk_2.pkl\n",
      "Processing chunk 3/28\n",
      "Chunk 3 saved as article_chunks\\article_hrefs_chunk_3.pkl\n",
      "Processing chunk 4/28\n",
      "Chunk 4 saved as article_chunks\\article_hrefs_chunk_4.pkl\n",
      "Processing chunk 5/28\n",
      "Chunk 5 saved as article_chunks\\article_hrefs_chunk_5.pkl\n",
      "Processing chunk 6/28\n",
      "Chunk 6 saved as article_chunks\\article_hrefs_chunk_6.pkl\n",
      "Processing chunk 7/28\n",
      "Chunk 7 saved as article_chunks\\article_hrefs_chunk_7.pkl\n",
      "Processing chunk 8/28\n",
      "Chunk 8 saved as article_chunks\\article_hrefs_chunk_8.pkl\n",
      "Processing chunk 9/28\n",
      "Chunk 9 saved as article_chunks\\article_hrefs_chunk_9.pkl\n",
      "Processing chunk 10/28\n",
      "Chunk 10 saved as article_chunks\\article_hrefs_chunk_10.pkl\n",
      "Processing chunk 11/28\n",
      "Chunk 11 saved as article_chunks\\article_hrefs_chunk_11.pkl\n",
      "Processing chunk 12/28\n",
      "Chunk 12 saved as article_chunks\\article_hrefs_chunk_12.pkl\n",
      "Processing chunk 13/28\n",
      "Chunk 13 saved as article_chunks\\article_hrefs_chunk_13.pkl\n",
      "Processing chunk 14/28\n",
      "Chunk 14 saved as article_chunks\\article_hrefs_chunk_14.pkl\n",
      "Processing chunk 15/28\n",
      "Chunk 15 saved as article_chunks\\article_hrefs_chunk_15.pkl\n",
      "Processing chunk 16/28\n",
      "Chunk 16 saved as article_chunks\\article_hrefs_chunk_16.pkl\n",
      "Processing chunk 17/28\n",
      "Chunk 17 saved as article_chunks\\article_hrefs_chunk_17.pkl\n",
      "Processing chunk 18/28\n",
      "Chunk 18 saved as article_chunks\\article_hrefs_chunk_18.pkl\n",
      "Processing chunk 19/28\n",
      "Chunk 19 saved as article_chunks\\article_hrefs_chunk_19.pkl\n",
      "Processing chunk 20/28\n",
      "Chunk 20 saved as article_chunks\\article_hrefs_chunk_20.pkl\n",
      "Processing chunk 21/28\n",
      "Chunk 21 saved as article_chunks\\article_hrefs_chunk_21.pkl\n",
      "Processing chunk 22/28\n",
      "Chunk 22 saved as article_chunks\\article_hrefs_chunk_22.pkl\n",
      "Processing chunk 23/28\n",
      "Chunk 23 saved as article_chunks\\article_hrefs_chunk_23.pkl\n",
      "Processing chunk 24/28\n",
      "Chunk 24 saved as article_chunks\\article_hrefs_chunk_24.pkl\n",
      "Processing chunk 25/28\n",
      "Chunk 25 saved as article_chunks\\article_hrefs_chunk_25.pkl\n",
      "Processing chunk 26/28\n",
      "Chunk 26 saved as article_chunks\\article_hrefs_chunk_26.pkl\n",
      "Processing chunk 27/28\n",
      "Chunk 27 saved as article_chunks\\article_hrefs_chunk_27.pkl\n",
      "Processing chunk 28/28\n",
      "Chunk 28 saved as article_chunks\\article_hrefs_chunk_28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create a new folder to save the chunks\n",
    "folder_name = 'article_chunks'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Process each chunk and save it as a .pkl file inside the new folder\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i + 1}/{len(chunks)}\")\n",
    "    \n",
    "    # Define the filepath for each chunk\n",
    "    filepath = os.path.join(folder_name, f\"article_hrefs_chunk_{i + 1}.pkl\")\n",
    "    \n",
    "    # Save the chunk to a .pkl file\n",
    "    with open(filepath, 'wb') as chunk_file:\n",
    "        pickle.dump(chunk, chunk_file)\n",
    "    \n",
    "    print(f\"Chunk {i + 1} saved as {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
