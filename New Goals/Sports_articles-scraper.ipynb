{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0746ce3-d2da-457d-aa12-32f7e39eb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException, NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import wget\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a01537-d47b-4448-a7dd-ecf2b51d7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ChromeDriver\n",
    "service = Service('E:/Programs/Chrome Driver/chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f44fd7e-096b-4695-a510-18b1d950439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the file path to load the data\n",
    "file_path = 'hrefs_with_categories.pkl'\n",
    "\n",
    "# Load the data using pickle\n",
    "with open(file_path, 'rb') as file:\n",
    "    hrefs_with_categories = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50b1a88-287e-48a4-bb9f-9b9b5169c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "for href, category in hrefs_with_categories:\n",
    "    if category.lower() == \"sports\":\n",
    "        driver.get(href)\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3549fd-c6bd-4638-91c3-7ea5773db6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of collected hrefs : 130\n"
     ]
    }
   ],
   "source": [
    "# getting primary page news\n",
    "# Initialize the list to store hrefs\n",
    "primary_hrefs = []\n",
    "\n",
    "# Define the XPath for the elements to extract the href\n",
    "xpath = ('//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_1\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"O1LaH\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_2\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"O1LaH\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_3\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"WavNE\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_13\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"O1LaH\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_4\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"WavNE\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_14\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"undefined\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_6\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"WavNE\", \" \" ))] | '\n",
    "         '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"card_5\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"O1LaH\", \" \" ))]')\n",
    "\n",
    "# Wait for the elements to be present\n",
    "try:\n",
    "    elements = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, xpath))\n",
    "    )\n",
    "\n",
    "    for element in elements:\n",
    "        try:\n",
    "            # Find the parent <a> tag\n",
    "            parent_a_tag = element.find_element(By.XPATH, \"./ancestor::a\")\n",
    "\n",
    "            # Extract the href attribute from the parent <a> tag\n",
    "            href = parent_a_tag.get_attribute('href')\n",
    "            \n",
    "            # Append the href to the primary_hrefs list if it exists\n",
    "            if href:\n",
    "                primary_hrefs.append(href)\n",
    "\n",
    "        except NoSuchElementException as e:\n",
    "            print(f\"Error retrieving href: {e}\")\n",
    "            continue\n",
    "\n",
    "except NoSuchElementException as e:\n",
    "    print(f\"Error locating elements: {e}\")\n",
    "\n",
    "# print(f\"Collected hrefs: {primary_hrefs}\")\n",
    "print(f\"The number of collected hrefs : {len(primary_hrefs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068fe386-3c77-40a2-a508-e27d54749ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected sports hrefs: ['https://timesofindia.indiatimes.com/sports/cricket', 'https://timesofindia.indiatimes.com/sports/football', 'https://timesofindia.indiatimes.com/sports/tennis', 'https://timesofindia.indiatimes.com/sports/wwe', 'https://timesofindia.indiatimes.com/sports/nfl', 'https://timesofindia.indiatimes.com/sports/hockey', 'https://timesofindia.indiatimes.com/sports/boxing', 'https://timesofindia.indiatimes.com/sports/golf']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list to store all sports hrefs\n",
    "all_sports_href = []\n",
    "\n",
    "# Simplified XPath to test for potential issues\n",
    "sports_xpath = ('//div[count(preceding-sibling::*) + 1 = 10]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 12]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 14]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//*[contains(@class, \"leaderboard_placeHolder\")]//div//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 18]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 20]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 25]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//*[contains(@class, \"baeqq\")]//*[contains(@class, \"o1wRt\")] | '\n",
    "                '//div[count(preceding-sibling::*) + 1 = 27]//*[contains(@class, \"o1wRt\")]')\n",
    "\n",
    "try:\n",
    "    # Wait for the elements to be present\n",
    "    sports_elements = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, sports_xpath))\n",
    "    )\n",
    "\n",
    "    for element in sports_elements:\n",
    "        try:\n",
    "            # Find the parent <a> tag\n",
    "            parent_a_tag = element.find_element(By.XPATH, \"./ancestor::a\")\n",
    "\n",
    "            # Extract the href attribute from the parent <a> tag\n",
    "            href = parent_a_tag.get_attribute('href')\n",
    "            \n",
    "            # Append the href to the all_sports_href list if it exists\n",
    "            if href:\n",
    "                all_sports_href.append(href)\n",
    "\n",
    "        except NoSuchElementException as e:\n",
    "            print(f\"Error retrieving href for an element: {e}\")\n",
    "            continue\n",
    "\n",
    "except (NoSuchElementException, InvalidSelectorException) as e:\n",
    "    print(f\"Error locating sports elements: {e}\")\n",
    "\n",
    "# Filter out any hrefs that end with '/sports'\n",
    "all_sports_href = [href for href in all_sports_href if not href.endswith('/sports')]\n",
    "\n",
    "# Print out the filtered all_sports_href list\n",
    "print(f\"Collected sports hrefs: {all_sports_href}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fac3ad-4bf9-4ec0-9866-33c338117d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigated to: https://timesofindia.indiatimes.com/sports/cricket\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/2\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/3\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/4\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/5\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/6\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/7\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/8\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/9\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/10\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/11\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/12\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/13\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/14\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/15\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/16\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/17\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/18\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/19\n",
      "Navigated to page: https://timesofindia.indiatimes.com/sports/cricket/20\n",
      "Number of collected cricket hrefs: 586\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/football\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Clicked 'Load More STORIES' button\n",
      "Load More button not found or clickable. Exiting.\n",
      "Collected Football Category hrefs: 6\n",
      "Collected Football hrefs: 9436\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/tennis\n",
      "Collected Tennis hrefs: 1371\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/wwe\n",
      "No more buttons to click in WWE, proceeding with href extraction.\n",
      "Collected number of WWE hrefs: 187\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/2\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/3\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/4\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/5\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/6\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/7\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/8\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/9\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/10\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/11\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/12\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/13\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/14\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/15\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/16\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/17\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/18\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/19\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/20\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/21\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/22\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/23\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/24\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/25\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/26\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/27\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/28\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/29\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/30\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/31\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/32\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/33\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/nfl/34\n",
      "Collected NFL hrefs: 1402\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/hockey\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/hockey\n",
      "Collected Hockey hrefs from page 1: 37\n",
      "Navigated to additional page: https://timesofindia.indiatimes.com/sports/hockey/hockey-world-cup\n",
      "Navigated to additional page: https://timesofindia.indiatimes.com/sports/hockey/hockey-world-cup/2\n",
      "Total collected Hockey hrefs: 87\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/boxing\n",
      "Collected Boxing hrefs: 42\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/2\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/3\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/4\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/5\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/6\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/7\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/8\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/9\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/10\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/11\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/12\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/13\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/14\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/15\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/16\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/17\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/18\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/19\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/20\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/21\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/22\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/23\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/24\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/25\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/26\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/27\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/28\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/29\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/30\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/31\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/32\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/33\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/34\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/35\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/36\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/37\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/38\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/39\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/40\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/41\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/42\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/43\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/44\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/45\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/46\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/47\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/48\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/49\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/50\n",
      "Navigated to: https://timesofindia.indiatimes.com/sports/golf/51\n",
      "Collected Golf hrefs: 5236\n"
     ]
    }
   ],
   "source": [
    "# Loop through each href in the all_sports_href list\n",
    "for href in all_sports_href:\n",
    "    try:\n",
    "        # Direct the driver to the first page of each link\n",
    "        driver.get(href)\n",
    "        \n",
    "        # Wait for the page to load completely\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\")) \n",
    "        )\n",
    "\n",
    "        # Print the current URL to verify navigation\n",
    "        print(f\"Navigated to: {driver.current_url}\")\n",
    "        \n",
    "        # Check if the current URL is the cricket page\n",
    "        if \"cricket\" in driver.current_url:\n",
    "            cricket_hrefs = []\n",
    "\n",
    "            # Define the XPath expressions for scraping\n",
    "            cricket_xpath = (\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"linktype2\", \" \"))] | '\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"col_m_3\", \" \"))]//figcaption | '\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"linktype1\", \" \"))]//span | '\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"sNF1c\", \" \"))] | '\n",
    "                '//h5 | '\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"BC4XY\", \" \"))]//a'\n",
    "            )\n",
    "\n",
    "            cricket_elements = driver.find_elements(By.XPATH, cricket_xpath)\n",
    "\n",
    "            for element in cricket_elements:\n",
    "                try:\n",
    "                    parent_a_tag = element.find_element(By.XPATH, \"./ancestor::a\")\n",
    "                    href = parent_a_tag.get_attribute('href')\n",
    "                    if href:\n",
    "                        cricket_hrefs.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            # Loop through pages 2 to 20 for the cricket section\n",
    "            for page_number in range(2, 21):\n",
    "                page_url = f\"https://timesofindia.indiatimes.com/sports/cricket/{page_number}\"\n",
    "                driver.get(page_url)\n",
    "\n",
    "                # Wait for the page to load\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "\n",
    "                # Print the current URL to verify navigation\n",
    "                print(f\"Navigated to page: {driver.current_url}\")\n",
    "\n",
    "                additional_cricket_xpath = '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"Jnjss\", \" \"))]'\n",
    "                additional_cricket_elements = driver.find_elements(By.XPATH, additional_cricket_xpath)\n",
    "\n",
    "                for element in additional_cricket_elements:\n",
    "                    try:\n",
    "                        parent_a_tag = element.find_element(By.XPATH, \"./ancestor::a\")\n",
    "                        href = parent_a_tag.get_attribute('href')\n",
    "                        if href:\n",
    "                            cricket_hrefs.append(href)\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "\n",
    "            print(f\"Number of collected cricket hrefs: {len(cricket_hrefs)}\")\n",
    "            \n",
    "        # Check if the current URL is the WWE page\n",
    "        elif \"wwe\" in driver.current_url:\n",
    "            while True:\n",
    "                try:\n",
    "                    button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"O92W7\", \" \"))]'))\n",
    "                    )\n",
    "                    button.click()\n",
    "                    time.sleep(1)  # Adjust sleep duration if necessary\n",
    "                except (NoSuchElementException, TimeoutException):\n",
    "                    print(\"No more buttons to click in WWE, proceeding with href extraction.\")\n",
    "                    break\n",
    "                    \n",
    "            wwe_hrefs = []\n",
    "\n",
    "            wwe_xpath = (\n",
    "                '//figcaption | '\n",
    "                '//h5 | '\n",
    "                '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"null\", \" \"))]//span'\n",
    "            )\n",
    "\n",
    "            wwe_elements = driver.find_elements(By.XPATH, wwe_xpath)\n",
    "\n",
    "            for element in wwe_elements:\n",
    "                try:\n",
    "                    parent_a_tag = element.find_element(By.XPATH, \"./ancestor::a\")\n",
    "                    href = parent_a_tag.get_attribute('href')\n",
    "                    if href:\n",
    "                        wwe_hrefs.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Collected number of WWE hrefs: {len(wwe_hrefs)}\")\n",
    "            \n",
    "        elif \"golf\" in driver.current_url:\n",
    "            golf_hrefs = []\n",
    "        \n",
    "            for i in range(1, 52):\n",
    "                golf_page_url = f\"https://timesofindia.indiatimes.com/sports/golf/{i}\"\n",
    "                \n",
    "                try:\n",
    "                    driver.get(golf_page_url)\n",
    "                    \n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"Navigated to: {driver.current_url}\")\n",
    "        \n",
    "                    golf_xpath = (\n",
    "                        '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"js-main-news-list\", \" \"))]'\n",
    "                        '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"clearfix\", \" \"))]//li//a'\n",
    "                    )\n",
    "\n",
    "        \n",
    "                    golf_elements = driver.find_elements(By.XPATH, golf_xpath)\n",
    "        \n",
    "                    for element in golf_elements:\n",
    "                        try:\n",
    "                            href = element.get_attribute('href')\n",
    "                            if href:\n",
    "                                golf_hrefs.append(href)\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error navigating to {golf_page_url}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "            print(f\"Collected Golf hrefs: {len(golf_hrefs)}\")\n",
    "            \n",
    "        elif \"boxing\" in driver.current_url:\n",
    "            boxing_hrefs = []\n",
    "            \n",
    "            boxing_xpath = (\n",
    "                '//*[@id=\"c_sport_wdt_1\"]//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"w_tle\", \" \"))]//a'\n",
    "            )\n",
    "\n",
    "            boxing_elements = driver.find_elements(By.XPATH, boxing_xpath)\n",
    "\n",
    "            for element in boxing_elements:\n",
    "                try:\n",
    "                    href = element.get_attribute('href')\n",
    "                    if href:\n",
    "                        boxing_hrefs.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            print(f\"Collected Boxing hrefs: {len(boxing_hrefs)}\")\n",
    "            \n",
    "        elif \"hockey\" in driver.current_url:\n",
    "            hockey_hrefs = []\n",
    "\n",
    "            # Loop through the main Hockey pages\n",
    "            for i in range(1, 2):  # Adjust the range as necessary\n",
    "                hockey_page_url = f\"https://timesofindia.indiatimes.com/sports/hockey/{i}\"\n",
    "                try:\n",
    "                    # Direct the driver to the hockey page\n",
    "                    driver.get(hockey_page_url)\n",
    "            \n",
    "                    # Wait for the page to load completely\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # Ensure page load\n",
    "                    )\n",
    "            \n",
    "                    # Print the current URL to verify navigation\n",
    "                    print(f\"Navigated to: {driver.current_url}\")\n",
    "            \n",
    "                    # Define the XPath expressions for scraping Hockey hrefs\n",
    "                    hockey_xpath = (\n",
    "                        '//*[@id=\"c_sport_wdt_1\"]//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"w_tle\", \" \"))]//a'\n",
    "                    )\n",
    "            \n",
    "                    # Find all elements using the specified XPath\n",
    "                    hockey_elements = driver.find_elements(By.XPATH, hockey_xpath)\n",
    "            \n",
    "                    # Extract hrefs from each element found\n",
    "                    for element in hockey_elements:\n",
    "                        try:\n",
    "                            # Extract href from the parent <a> tag\n",
    "                            href = element.get_attribute('href')\n",
    "                            if href:\n",
    "                                hockey_hrefs.append(href)\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "            \n",
    "                    print(f\"Collected Hockey hrefs from page {i}: {len(hockey_elements)}\")\n",
    "            \n",
    "                    # Click the button to load additional content if available\n",
    "                    try:\n",
    "                        button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.XPATH, '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"sweep-button\", \" \"))]//a'))\n",
    "                        )\n",
    "                        clicked_url = button.get_attribute('href') \n",
    "                        button.click()\n",
    "                        time.sleep(1)  # Wait for the new content to load\n",
    "                    except (NoSuchElementException, TimeoutException):\n",
    "                        print(\"No button to click for more hockey content or the button is not clickable.\")\n",
    "            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error navigating to {hockey_page_url}: {e}\")\n",
    "            \n",
    "            # Navigate to additional pages (/1 and /2) after clicking the button\n",
    "            for page_number in range(1, 3):  # Adjust the range as necessary\n",
    "                new_hockey_page_url = f\"{clicked_url}/{page_number}\"\n",
    "                driver.get(new_hockey_page_url)\n",
    "                \n",
    "                # Wait for the new page to load\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # Ensure page load\n",
    "                )\n",
    "                \n",
    "                # Print the current URL to verify navigation\n",
    "                print(f\"Navigated to additional page: {driver.current_url}\")\n",
    "            \n",
    "                # Find all elements using the same XPath for additional pages\n",
    "                hockey_elements = driver.find_elements(By.XPATH, hockey_xpath)\n",
    "            \n",
    "                # Extract hrefs from each element found on the additional page\n",
    "                for element in hockey_elements:\n",
    "                    try:\n",
    "                        # Extract href from the parent <a> tag\n",
    "                        href = element.get_attribute('href')\n",
    "                        if href:\n",
    "                            hockey_hrefs.append(href)\n",
    "                    except NoSuchElementException:\n",
    "                        continue\n",
    "            \n",
    "            # Print the total number of collected Hockey hrefs\n",
    "            print(f\"Total collected Hockey hrefs: {len(hockey_hrefs)}\")\n",
    "\n",
    "        elif \"nfl\" in driver.current_url:\n",
    "            nfl_hrefs = []\n",
    "            \n",
    "            # Get the current URL\n",
    "            current_url = driver.current_url\n",
    "            \n",
    "            # Loop through pages from 1 to 34\n",
    "            for page_number in range(1, 35):  # 1 to 34\n",
    "                nfl_page_url = f\"{current_url}/{page_number}\"  # Construct the page URL\n",
    "                try:\n",
    "                    # Direct the driver to the NFL page\n",
    "                    driver.get(nfl_page_url)\n",
    "        \n",
    "                    # Optionally, wait for the page to load completely\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.TAG_NAME, \"body\"))  # Ensure page load\n",
    "                    )\n",
    "        \n",
    "                    # Print the current URL to verify navigation\n",
    "                    print(f\"Navigated to: {driver.current_url}\")\n",
    "        \n",
    "                    # Define the XPath expressions for scraping NFL hrefs\n",
    "                    nfl_xpath = (\n",
    "                        '//*[@id=\"c_sport_wdt_1\"]//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"w_tle\", \" \"))]//a'\n",
    "                    )\n",
    "        \n",
    "                    # Find all elements using the specified XPath\n",
    "                    nfl_elements = driver.find_elements(By.XPATH, nfl_xpath)\n",
    "        \n",
    "                    # Extract hrefs from each element found\n",
    "                    for element in nfl_elements:\n",
    "                        try:\n",
    "                            # Extract href from the parent <a> tag\n",
    "                            href = element.get_attribute('href')\n",
    "                            if href:\n",
    "                                nfl_hrefs.append(href)\n",
    "                        except NoSuchElementException:\n",
    "                            continue\n",
    "        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error navigating to {nfl_page_url}: {e}\")\n",
    "        \n",
    "            # Print collected NFL hrefs\n",
    "            print(f\"Collected NFL hrefs: {len(nfl_hrefs)}\")\n",
    "\n",
    "        elif \"tennis\" in driver.current_url:\n",
    "            tennis_hrefs = []\n",
    "            tennis_categories = driver.find_elements(By.XPATH, '//h2[contains(@class, \"peJf5\")]//a[contains(@class, \"HjSby\")]')\n",
    "            tennis_categories_href = []\n",
    "            \n",
    "            # Extract hrefs from the <a> tags inside the <h2> elements\n",
    "            for category in tennis_categories:\n",
    "                try:\n",
    "                    href = category.get_attribute('href')\n",
    "                    if href:\n",
    "                        tennis_categories_href.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "        \n",
    "            # Iterate through the hrefs in tennis_categories_href\n",
    "            for href in tennis_categories_href:\n",
    "                for i in range(1, 34):  # Loop through the pages (up to 33)\n",
    "                    driver.get(f\"{href}/{i}\")\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "                    # Find elements in the js-main-news-list with the parent <a> tag whose href needs to be collected\n",
    "                    tennis_elements = driver.find_elements(By.XPATH, '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"js-main-news-list\", \" \"))]//li//a')\n",
    "                    \n",
    "                    # Extract the hrefs from these <a> elements\n",
    "                    for element in tennis_elements:\n",
    "                        href = element.get_attribute('href')\n",
    "                        if href:\n",
    "                            tennis_hrefs.append(href)\n",
    "        \n",
    "            print(f\"Collected Tennis hrefs: {len(tennis_hrefs)}\")\n",
    "\n",
    "        elif \"football\" in driver.current_url:\n",
    "            # List to hold football hrefs and category hrefs\n",
    "            football_hrefs = []\n",
    "            football_categories_href = []\n",
    "            \n",
    "            # Click the 'Load More STORIES' button until it's no longer available\n",
    "            while True:\n",
    "                try:\n",
    "                    load_more_button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, '//button[contains(@class, \"O92W7\")]'))\n",
    "                    )\n",
    "                    load_more_button.click()\n",
    "                    print(\"Clicked 'Load More STORIES' button\")\n",
    "            \n",
    "                    # Wait for new content to load\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "                    time.sleep(1)  # Optional: short wait after clicking\n",
    "            \n",
    "                except TimeoutException:\n",
    "                    print(\"Load More button not found or clickable. Exiting.\")\n",
    "                    break\n",
    "                except StaleElementReferenceException:\n",
    "                    print(\"StaleElementReferenceException encountered. Retrying to find the button...\")\n",
    "                    continue  # Retry the loop to find and click again\n",
    "                except (NoSuchElementException, ElementClickInterceptedException):\n",
    "                    print(\"No more 'Load More STORIES' button to click.\")\n",
    "                    break\n",
    "\n",
    "            \n",
    "            # Once all the content is loaded, collect hrefs from the specified elements\n",
    "            football_elements = driver.find_elements(By.XPATH, \n",
    "                '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"col_l_4\", \" \" ))]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"hoid1\", \" \" ))]//figcaption | '\n",
    "                '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"null\", \" \" ))]//span'\n",
    "            )\n",
    "            # Extract hrefs from the parent <a> tags of these elements\n",
    "            for element in football_elements:\n",
    "                try:\n",
    "                    parent_a_tag = element.find_element(By.XPATH, './ancestor::a')\n",
    "                    href = parent_a_tag.get_attribute('href')\n",
    "                    if href:\n",
    "                        football_hrefs.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "            \n",
    "            # Collect category hrefs from the elements matching the second XPath\n",
    "            football_categories = driver.find_elements(By.XPATH, '//*[contains(concat(\" \", @class, \" \"), concat(\" \", \"xhx_z\", \" \"))]')\n",
    "            \n",
    "            # Extract hrefs from the parent <a> tags of these category elements\n",
    "            for category in football_categories:\n",
    "                try:\n",
    "                    parent_a_tag = category.find_element(By.XPATH, './ancestor::a')\n",
    "                    href = parent_a_tag.get_attribute('href')\n",
    "                    if href:\n",
    "                        football_categories_href.append(href)\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "\n",
    "            print(f\"Collected Football Category hrefs: {len(football_categories_href)}\")\n",
    "\n",
    "            # Iterate through each category href\n",
    "            for category_href in football_categories_href:\n",
    "                for page_number in range(1, 61):  # Loop through pages 1 to 60\n",
    "                    # Construct the URL for each page\n",
    "                    page_url = f\"{category_href}/{page_number}\"\n",
    "                    driver.get(page_url)\n",
    "            \n",
    "                    # Wait for the page to load\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "            \n",
    "                    try:\n",
    "                        # Get hrefs from the specified elements\n",
    "                        football_elements = driver.find_elements(By.XPATH, \n",
    "                            '//*[(@id = \"c_sport_wdt_1\")]//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"w_tle\", \" \" ))]//a'\n",
    "                        )\n",
    "            \n",
    "                        # Extract hrefs and store them in the list\n",
    "                        if football_elements:  # Check if any elements were found\n",
    "                            for element in football_elements:\n",
    "                                href = element.get_attribute('href')\n",
    "                                if href:\n",
    "                                    football_hrefs.append(href)\n",
    "                    except NoSuchElementException:\n",
    "                        # If no elements are found, continue to the next page indentation\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        # Optionally, log or print the error\n",
    "                        print(f\"Error accessing {page_url}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            # Print the number of collected hrefs\n",
    "            print(f\"Collected Football hrefs: {len(football_hrefs)}\")\n",
    "            \n",
    "            # Optional: Print the first few hrefs to check the results\n",
    "            # print(football_hrefs[:10])\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating to {href}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6acb347-8bef-4d19-b579-422c929df57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Cricket Hrefs: 586\n",
      "Collected WWE Hrefs: 187\n",
      "Collected Golf Hrefs: 5236\n",
      "Collected Boxing Hrefs: 42\n",
      "Collected Hockey Hrefs: 87\n",
      "Collected NFL Hrefs: 1402\n",
      "Collected Football Hrefs: 9436\n",
      "Collected Tennis Hrefs: 1371\n"
     ]
    }
   ],
   "source": [
    "print(f\"Collected Cricket Hrefs: {len(cricket_hrefs)}\")\n",
    "print(f\"Collected WWE Hrefs: {len(wwe_hrefs)}\")\n",
    "print(f\"Collected Golf Hrefs: {len(golf_hrefs)}\")\n",
    "print(f\"Collected Boxing Hrefs: {len(boxing_hrefs)}\")\n",
    "print(f\"Collected Hockey Hrefs: {len(hockey_hrefs)}\")\n",
    "print(f\"Collected NFL Hrefs: {len(nfl_hrefs)}\")\n",
    "print(f\"Collected Football Hrefs: {len(football_hrefs)}\")\n",
    "print(f\"Collected Tennis Hrefs: {len(tennis_hrefs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29041850-77ac-4b05-9c35-d65fc3d7377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Collected Hrefs: 18347\n"
     ]
    }
   ],
   "source": [
    "# Combine all the href lists into a single list\n",
    "all_hrefs = (\n",
    "    cricket_hrefs + \n",
    "    wwe_hrefs + \n",
    "    golf_hrefs + \n",
    "    boxing_hrefs + \n",
    "    hockey_hrefs + \n",
    "    nfl_hrefs + \n",
    "    tennis_hrefs + \n",
    "    football_hrefs\n",
    ")\n",
    "\n",
    "# Print the total number of collected hrefs\n",
    "print(f\"Total Collected Hrefs: {len(all_hrefs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a077fe9f-91eb-4a12-ba7c-ba0e3d04ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs_with_pairs = [[href, \"NA\"] for href in all_hrefs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a722954a-2637-4264-8c31-7bbdff9affd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links saved to education_hrefs.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the list to a file using pickle\n",
    "with open('articles_from_sports.pkl', 'wb') as f:\n",
    "    pickle.dump(hrefs_with_pairs, f)\n",
    "\n",
    "print(\"Links saved to education_hrefs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d203ef-b54a-46e7-b857-726db0d8050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
